{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea7269fb-38b9-4699-b622-ee626548e7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a935c14e-8930-4bae-9b9d-bba95590fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad4d18a-2060-42e8-b2d0-73c626773fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep import X_train_1, X_test_1, y_train_1, y_test_1, X_train_2, X_test_2, y_train_2, y_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff21c22-f4c2-427f-b2a4-9bfd14529545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "model_name = 'Logistic Regression'\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "with mlflow.start_run(run_name=f\"{model_name}_fraud_data\"):\n",
    "    \n",
    "    # Train on the fraud dataset\n",
    "    model.fit(X_train_1, y_train_1)\n",
    "    y_pred_1 = model.predict(X_test_1)\n",
    "    \n",
    "    # Log metrics\n",
    "    accuracy_1 = accuracy_score(y_test_1, y_pred_1)\n",
    "    f1_1 = f1_score(y_test_1, y_pred_1)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_1)\n",
    "    mlflow.log_metric(\"f1_score\", f1_1)\n",
    "\n",
    "    # Log the model\n",
    "    signature_1 = infer_signature(X_train_1, y_pred_1)\n",
    "    mlflow.sklearn.log_model(\n",
    "        model, model_name + \"fraud_data\",\n",
    "        signature=signature_1,\n",
    "        input_example=X_train_1.head(5)\n",
    "    )\n",
    "\n",
    "    print(f\"{model_name} fraud_Data: Accuracy = {accuracy_1}, F1 Score = {f1_1}\")\n",
    "\n",
    "#Dataset 2 - Fine-tuning\n",
    "with mlflow.start_run(run_name=f\"{model_name}_dataset2\"):\n",
    "    \n",
    "    # Fine-tune on the credit dataset\n",
    "    model.fit(X_train_2, y_train_2)\n",
    "    y_pred_2 = model.predict(X_test_2)\n",
    "    \n",
    "    # Log metrics\n",
    "    accuracy_2 = accuracy_score(y_test_2, y_pred_2)\n",
    "    f1_2 = f1_score(y_test_2, y_pred_2)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_2)\n",
    "    mlflow.log_metric(\"f1_score\", f1_2)\n",
    "\n",
    "    # Log the model\n",
    "    signature_2 = infer_signature(X_train_2, y_pred_2)\n",
    "    mlflow.sklearn.log_model(\n",
    "        model, model_name + \"credit\",\n",
    "        signature=signature_2,\n",
    "        input_example=X_train_2.head(5)\n",
    "    )\n",
    "\n",
    "    print(f\"{model_name} credit : Accuracy = {accuracy_2}, F1 Score = {f1_2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8697c951-52d2-4553-9b98-047d39b2bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "def train_and_log_decision_tree(X, y, dataset_name):\n",
    "    # Split dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Define parameter grid for fine-tuning\n",
    "    param_grid = {\n",
    "        'max_depth': [5, 10, 15, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['auto', 'sqrt', 'log2']\n",
    "    }\n",
    "\n",
    "    # Initialize model and GridSearchCV for tuning\n",
    "    tree_model = DecisionTreeClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=tree_model, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "\n",
    "    # Train and tune the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_tree_model = grid_search.best_estimator_\n",
    "    y_pred = best_tree_model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"Dataset: {dataset_name} | Accuracy: {accuracy}, F1 Score: {f1}\")\n",
    "\n",
    "    # Log the model and metrics with MLflow\n",
    "    with mlflow.start_run(run_name=f'Decision Tree on {dataset_name}'):\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        \n",
    "        # Infer model signature\n",
    "        signature = infer_signature(X_train, y_pred)\n",
    "        mlflow.sklearn.log_model(\n",
    "            best_tree_model, f\"Decision Tree - {dataset_name}\",\n",
    "            signature=signature,\n",
    "            input_example=X_train.head(5)\n",
    "        )\n",
    "\n",
    "# Example usage for two datasets: X1, y1 and X2, y2\n",
    "train_and_log_decision_tree(X1, y1, \"Dataset 1\")\n",
    "train_and_log_decision_tree(X2, y2, \"Dataset 2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda Environment",
   "language": "python",
   "name": "anaconda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
